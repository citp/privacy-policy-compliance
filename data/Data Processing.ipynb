{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "annots_folder = \"OPP-115/consolidation/threshold-0.75-overlap-similarity/\"\n",
    "sample_data_folder = \"sample/\"\n",
    "output_folder = \"training_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tags_recursively(d,prev_keys):\n",
    "    selected_text = \"\"\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            yield from parse_tags_recursively(v,prev_keys+\"=>\"+k)\n",
    "        else:\n",
    "            if k == \"value\":\n",
    "                yield(\"{0}=>{1}\".format(prev_keys,v))\n",
    "            elif k == \"selectedText\":\n",
    "                selected_text = \"{0}\".format(v)\n",
    "                \n",
    "    yield selected_text\n",
    "\n",
    "def parse_tags_wrapper(d,prev_keys):\n",
    "    tags = list(parse_tags_recursively(d,prev_keys))\n",
    "    l = list(zip(tags[1::2],tags[::2]))\n",
    "    d = dict()\n",
    "    [d [t [0]].append(t [1]) if t [0] in list(d.keys()) else d.update({t [0]: [t [1]]}) for t in l]\n",
    "    return d\n",
    "\n",
    "def get_longest_list_in_dict_vals(d):\n",
    "    longest = 0\n",
    "    for k,v in d.items():\n",
    "        if len(v) > longest:\n",
    "            longest = len(v)\n",
    "    \n",
    "    return longest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('By interacting with Barnes & Noble in the manner described in this Privacy Policy at any time, you are accepting the practices described in this Privacy Policy and you consent to the application of this Privacy Policy to the collection, storage, use and disclosure of all your personal and other information as described.', 'User Choice/Control=>Choice Type=>Dont use service/feature'), ('disclosure of all your personal', 'User Choice/Control=>Choice Scope=>Third party sharing/collection'), ('', 'User Choice/Control=>User Type=>Unspecified'), ('', 'User Choice/Control=>Purpose=>Unspecified'), ('personal and other information', 'User Choice/Control=>Personal Information Type=>Generic personal information')]\n",
      "{'By interacting with Barnes & Noble in the manner described in this Privacy Policy at any time, you are accepting the practices described in this Privacy Policy and you consent to the application of this Privacy Policy to the collection, storage, use and disclosure of all your personal and other information as described.': ['User Choice/Control=>Choice Type=>Dont use service/feature'], 'disclosure of all your personal': ['User Choice/Control=>Choice Scope=>Third party sharing/collection'], '': ['User Choice/Control=>User Type=>Unspecified', 'User Choice/Control=>Purpose=>Unspecified'], 'personal and other information': ['User Choice/Control=>Personal Information Type=>Generic personal information']}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>By interacting with Barnes &amp; Noble in the manner described in this Privacy Policy at any time, you are accepting the practices described in this Privacy Policy and you consent to the application of this Privacy Policy to the collection, storage, use and disclosure of all your personal and other information as described.</th>\n",
       "      <td>User Choice/Control=&gt;Choice Type=&gt;Dont use ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disclosure of all your personal</th>\n",
       "      <td>User Choice/Control=&gt;Choice Scope=&gt;Third party...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personal and other information</th>\n",
       "      <td>User Choice/Control=&gt;Personal Information Type...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    0\n",
       "By interacting with Barnes & Noble in the manne...  User Choice/Control=>Choice Type=>Dont use ser...\n",
       "disclosure of all your personal                     User Choice/Control=>Choice Scope=>Third party...\n",
       "personal and other information                      User Choice/Control=>Personal Information Type..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TESTING SANDBOX ###\n",
    "filename = \"453_barnesandnoble.com.csv\"\n",
    "df_test = pd.read_csv(annots_folder+filename, names=[\"annot_id\",\"batch_id\",\"annotator_id\",\"policy_id\",\"segment_id\",\"category\",\"tags\",\"url\",\"date\"])\n",
    "df_test.set_index(\"annot_id\",inplace=True)\n",
    "df_test.drop(['batch_id','annotator_id','url','date'],inplace=True,axis=1)\n",
    "        \n",
    "i = 13\n",
    "tag_dict = json.loads(df_test['tags'][i])\n",
    "tag_cat = df_test['category'][i]\n",
    "\n",
    "d = parse_tags_wrapper(tag_dict,tag_cat)\n",
    "del d['']\n",
    "\n",
    "#print(json.dumps(tag_dict,indent=1))\n",
    "#print(\"\\n\")\n",
    "#print(json.dumps(d,indent=1))\n",
    "\n",
    "df = pd.DataFrame.from_dict(d,orient='index')#,columns=[''])\n",
    "df\n",
    "#df_ohe = pd.get_dummies(df)\n",
    "#df_ohe.columns = df_ohe.columns.str.lstrip(\"_\")\n",
    "#df_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERATE TRAINING DATA ##\n",
    "\n",
    "master_df = pd.DataFrame()\n",
    "\n",
    "for filename in os.listdir(annots_folder):\n",
    "    if filename.endswith(\".csv\"):           \n",
    "        df_in = pd.read_csv(annots_folder+filename, names=[\"annot_id\",\"batch_id\",\"annotator_id\",\"policy_id\",\"segment_id\",\"category\",\"tags\",\"url\",\"date\"])\n",
    "        df_in.set_index(\"annot_id\",inplace=True)\n",
    "        df_in.drop(['batch_id','annotator_id','url','date'],inplace=True,axis=1)\n",
    "        \n",
    "        rows = {}\n",
    "        for index, row in df_in.iterrows():\n",
    "            rows.update(parse_tags_wrapper(json.loads(row['tags']),row['category']))\n",
    "        \n",
    "        try:\n",
    "            del rows['null']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            del rows['Not selected']\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        df_temp = pd.DataFrame.from_dict(rows,orient='index',columns=['']*get_longest_list_in_dict_vals(rows))\n",
    "        master_df = pd.concat([master_df,df_temp],axis=1,sort=True)\n",
    "\n",
    "df_ohe = pd.get_dummies(master_df)\n",
    "df_ohe.columns = df_ohe.columns.str.lstrip(\"_\")\n",
    "df_ohe = df_ohe.groupby(df_ohe.columns, axis=1).agg(np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe.to_csv(\"spans_and_labels_OHE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: 3663\n"
     ]
    }
   ],
   "source": [
    "## GENERATE PREDICTION DATA ##\n",
    "all_tokens = []\n",
    "num_failed = 0\n",
    "\n",
    "for filename in os.listdir(sample_data_folder):\n",
    "    try:\n",
    "        if filename.endswith(\".txt\"):\n",
    "            text = open(sample_data_folder+filename).read()\n",
    "            tokens = tokenize.sent_tokenize(text)\n",
    "            all_tokens.extend(tokens)\n",
    "            #print(\"Processed \" + filename)\n",
    "    except:\n",
    "        num_failed += 1\n",
    "        \n",
    "print(\"Failed: \" + str(num_failed))\n",
    "all_tokens = list(set(all_tokens))\n",
    "\n",
    "#p = \"Good morning Dr. Adams. The patient is waiting for you in room number 3.\"\n",
    "#tokenize.sent_tokenize(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = [s.replace('\\n', ' ').replace('\\r', '').strip().encode('ascii',errors='ignore').decode() for s in all_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample_tokens.txt', 'w') as f:\n",
    "    for item in token_list:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token_list[3])\n",
    "#str(all_tokens[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
